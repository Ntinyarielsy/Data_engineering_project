# Data_engineering_project
I followed an end-to-end data engineering project offered by Data Talk Club where I dived into various aspect of data life cycle.The project encompassed the design and implementation of robust ETL pipelines, intricate data modeling, and efficient batch and stream data processing.

Throughout the project, I used tools to improve and enhance IT. Prefect was instrumental in ETL orchestration, enabling smooth workflow management and monitoring. Docker has played a key role in containerizing our applications, ensuring consistency across  environments and making deployment easier. 
 
In batch processing, I harnessed the power of Apache Spark and used its distributed computing capabilities to efficiently process large-scale data transformations. 
